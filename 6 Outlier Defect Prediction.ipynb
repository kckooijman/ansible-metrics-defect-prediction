{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after dropping na columns and rows:  (9285, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atss_count</th>\n",
       "      <th>bloc_count</th>\n",
       "      <th>bloc_count_relative</th>\n",
       "      <th>cloc_count</th>\n",
       "      <th>cloc_count_relative</th>\n",
       "      <th>dpt_count</th>\n",
       "      <th>etp_count</th>\n",
       "      <th>loc_count</th>\n",
       "      <th>nbeh_count</th>\n",
       "      <th>nbeh_count_relative</th>\n",
       "      <th>...</th>\n",
       "      <th>nsh_count</th>\n",
       "      <th>ntkn_count</th>\n",
       "      <th>ntnn_count</th>\n",
       "      <th>ntnn_count_relative</th>\n",
       "      <th>nts_count</th>\n",
       "      <th>ntun_count</th>\n",
       "      <th>ntun_count_relative</th>\n",
       "      <th>ntvr_count</th>\n",
       "      <th>nun_count</th>\n",
       "      <th>nun_count_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.81</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.30</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   atss_count  bloc_count  bloc_count_relative  cloc_count  \\\n",
       "0         3.0           0                  0.0           0   \n",
       "1        10.0           0                  0.0           0   \n",
       "2         9.0           0                  0.0           2   \n",
       "3         6.0           0                  0.0           0   \n",
       "4        13.0           0                  0.0           0   \n",
       "\n",
       "   cloc_count_relative  dpt_count  etp_count  loc_count  nbeh_count  \\\n",
       "0                 0.00          2      -5.81         25         0.0   \n",
       "1                 0.00          2      -4.01         10         0.0   \n",
       "2                 0.02          5      -5.57        132         0.0   \n",
       "3                 0.00          2      -5.34         37         0.0   \n",
       "4                 0.00          3      -4.30         13         0.0   \n",
       "\n",
       "   nbeh_count_relative  ...  nsh_count  ntkn_count  ntnn_count  \\\n",
       "0                  0.0  ...        5.0         113         1.0   \n",
       "1                  0.0  ...        0.0          31         0.0   \n",
       "2                  0.0  ...        0.0         373         0.0   \n",
       "3                  0.0  ...        1.0         133         0.0   \n",
       "4                  0.0  ...        0.0          34         1.0   \n",
       "\n",
       "   ntnn_count_relative  nts_count  ntun_count  ntun_count_relative  \\\n",
       "0                 0.11        9.0         8.0                 0.89   \n",
       "1                 0.00        1.0         1.0                 1.00   \n",
       "2                 0.00       15.0         7.0                 0.47   \n",
       "3                 0.00        6.0         6.0                 1.00   \n",
       "4                 1.00        1.0         0.0                 0.00   \n",
       "\n",
       "   ntvr_count  nun_count  nun_count_relative  \n",
       "0         5.0        8.0                1.00  \n",
       "1         5.0        2.0                1.00  \n",
       "2         8.0        7.0                0.29  \n",
       "3         4.0        6.0                1.00  \n",
       "4         2.0        2.0                1.00  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load necessary data, drop irrelevant columns\n",
    "data = pd.read_csv('results/output.csv')\n",
    "outlier_data = pd.read_csv('results/results_with_outliers.csv')\n",
    "\n",
    "filenames = data['file']\n",
    "data = data.drop(columns = 'file')\n",
    "\n",
    "to_drop = ['apls_count', 'niu_count', 'npl_count', 'npnn_count', \n",
    "           'npnn_count_relative', 'npun_count', 'npun_count_relative', \n",
    "           'npvr_count', 'nrgv_count', 'nrl_count', 'nrvr_count', \n",
    "           'nvr_count', 'nscm_count', 'nmo_count', 'nimpp_count']\n",
    "\n",
    "data = data.drop(columns=to_drop)\n",
    "data = data.dropna()\n",
    "print(\"Data shape after dropping na columns and rows: \", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = outlier_data\n",
    "all_metrics = all_metrics.drop(columns=['outlier_scores', 'file'])\n",
    "\n",
    "relative_cols = [col for col in data.columns if 'relative' in col]\n",
    "absolute = outlier_data.drop(columns = relative_cols)\n",
    "absolute = absolute.drop(columns=['outlier_scores', 'file'])\n",
    "\n",
    "absolute_cols = [col.strip('relative').rstrip('_') for col in relative_cols]\n",
    "relative = outlier_data.drop(columns = absolute_cols)\n",
    "relative = relative.drop(columns=['outlier_scores', 'file'])\n",
    "\n",
    "no_corr_cols = ['ncd_count', 'nkeys_count', 'nnnv_count', 'ntkn_count', 'nun_count', 'nco_count',\n",
    "               'nemd_count', 'ntun_count', 'ntnn_count_relative', 'nts_count', 'ntvr_count']\n",
    "no_corr_metrics = outlier_data.drop(columns=no_corr_cols)\n",
    "no_corr_metrics = no_corr_metrics.drop(columns=['outlier_scores', 'file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_metrics\n",
      "RandomForestClassifier Imp Accuracy:  0.5081967213114754\n",
      "RandomForestClassifier Imp Precision:  0.5\n",
      "RandomForestClassifier Imp Recall:  0.1\n",
      "RandomForestClassifier Imp fscore:  0.16666666666666669\n",
      "RandomForestClassifier all Accuracy:  0.5245901639344263\n",
      "RandomForestClassifier all Precision:  0.5714285714285714\n",
      "RandomForestClassifier all Recall:  0.13333333333333333\n",
      "RandomForestClassifier all fscore:  0.21621621621621623\n",
      "Decision Tree Imp Accuracy:  0.4918032786885246\n",
      "Decision Tree Imp Precision:  0.4444444444444444\n",
      "Decision Tree Imp Recall:  0.13333333333333333\n",
      "Decision Tree Imp fscore:  0.20512820512820512\n",
      "Decision Tree all Accuracy:  0.5081967213114754\n",
      "Decision Tree all Precision:  0.5\n",
      "Decision Tree all Recall:  0.2\n",
      "Decision Tree all fscore:  0.28571428571428575\n",
      "Naive Bayes Imp Accuracy:  0.4918032786885246\n",
      "Naive Bayes Imp Precision:  0.4444444444444444\n",
      "Naive Bayes Imp Recall:  0.13333333333333333\n",
      "Naive Bayes Imp fscore:  0.20512820512820512\n",
      "Naive Bayes all Accuracy:  0.4918032786885246\n",
      "Naive Bayes all Precision:  0.48148148148148145\n",
      "Naive Bayes all Recall:  0.43333333333333335\n",
      "Naive Bayes all fscore:  0.456140350877193\n",
      "MLP Imp Accuracy:  0.4918032786885246\n",
      "MLP Imp Precision:  0.4918032786885246\n",
      "MLP Imp Recall:  1.0\n",
      "MLP Imp fscore:  0.6593406593406593\n",
      "MLP all Accuracy:  0.4918032786885246\n",
      "MLP all Precision:  0.4918032786885246\n",
      "MLP all Recall:  1.0\n",
      "MLP all fscore:  0.6593406593406593\n",
      "\n",
      "absolute\n",
      "RandomForestClassifier Imp Accuracy:  0.4918032786885246\n",
      "RandomForestClassifier Imp Precision:  0.4\n",
      "RandomForestClassifier Imp Recall:  0.06666666666666667\n",
      "RandomForestClassifier Imp fscore:  0.1142857142857143\n",
      "RandomForestClassifier all Accuracy:  0.5245901639344263\n",
      "RandomForestClassifier all Precision:  0.5714285714285714\n",
      "RandomForestClassifier all Recall:  0.13333333333333333\n",
      "RandomForestClassifier all fscore:  0.21621621621621623\n",
      "Decision Tree Imp Accuracy:  0.47540983606557374\n",
      "Decision Tree Imp Precision:  0.42857142857142855\n",
      "Decision Tree Imp Recall:  0.2\n",
      "Decision Tree Imp fscore:  0.27272727272727276\n",
      "Decision Tree all Accuracy:  0.5245901639344263\n",
      "Decision Tree all Precision:  0.5714285714285714\n",
      "Decision Tree all Recall:  0.13333333333333333\n",
      "Decision Tree all fscore:  0.21621621621621623\n",
      "Naive Bayes Imp Accuracy:  0.5081967213114754\n",
      "Naive Bayes Imp Precision:  0.5\n",
      "Naive Bayes Imp Recall:  0.1\n",
      "Naive Bayes Imp fscore:  0.16666666666666669\n",
      "Naive Bayes all Accuracy:  0.5245901639344263\n",
      "Naive Bayes all Precision:  0.52\n",
      "Naive Bayes all Recall:  0.43333333333333335\n",
      "Naive Bayes all fscore:  0.4727272727272728\n",
      "MLP Imp Accuracy:  0.4918032786885246\n",
      "MLP Imp Precision:  0.4918032786885246\n",
      "MLP Imp Recall:  1.0\n",
      "MLP Imp fscore:  0.6593406593406593\n",
      "MLP all Accuracy:  0.5081967213114754\n",
      "MLP all Precision:  0.0\n",
      "MLP all Recall:  0.0\n",
      "MLP all fscore:  0.0\n",
      "\n",
      "relative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Imp Accuracy:  0.5081967213114754\n",
      "RandomForestClassifier Imp Precision:  0.5\n",
      "RandomForestClassifier Imp Recall:  0.1\n",
      "RandomForestClassifier Imp fscore:  0.16666666666666669\n",
      "RandomForestClassifier all Accuracy:  0.4918032786885246\n",
      "RandomForestClassifier all Precision:  0.4\n",
      "RandomForestClassifier all Recall:  0.06666666666666667\n",
      "RandomForestClassifier all fscore:  0.1142857142857143\n",
      "Decision Tree Imp Accuracy:  0.45901639344262296\n",
      "Decision Tree Imp Precision:  0.36363636363636365\n",
      "Decision Tree Imp Recall:  0.13333333333333333\n",
      "Decision Tree Imp fscore:  0.1951219512195122\n",
      "Decision Tree all Accuracy:  0.5081967213114754\n",
      "Decision Tree all Precision:  0.5\n",
      "Decision Tree all Recall:  0.1\n",
      "Decision Tree all fscore:  0.16666666666666669\n",
      "Naive Bayes Imp Accuracy:  0.5081967213114754\n",
      "Naive Bayes Imp Precision:  0.5\n",
      "Naive Bayes Imp Recall:  0.2\n",
      "Naive Bayes Imp fscore:  0.28571428571428575\n",
      "Naive Bayes all Accuracy:  0.5081967213114754\n",
      "Naive Bayes all Precision:  0.5\n",
      "Naive Bayes all Recall:  0.43333333333333335\n",
      "Naive Bayes all fscore:  0.4642857142857143\n",
      "MLP Imp Accuracy:  0.4918032786885246\n",
      "MLP Imp Precision:  0.4918032786885246\n",
      "MLP Imp Recall:  1.0\n",
      "MLP Imp fscore:  0.6593406593406593\n",
      "MLP all Accuracy:  0.5081967213114754\n",
      "MLP all Precision:  0.0\n",
      "MLP all Recall:  0.0\n",
      "MLP all fscore:  0.0\n",
      "\n",
      "no_corr_metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Imp Accuracy:  0.5081967213114754\n",
      "RandomForestClassifier Imp Precision:  0.5\n",
      "RandomForestClassifier Imp Recall:  0.06666666666666667\n",
      "RandomForestClassifier Imp fscore:  0.11764705882352941\n",
      "RandomForestClassifier all Accuracy:  0.5245901639344263\n",
      "RandomForestClassifier all Precision:  0.6\n",
      "RandomForestClassifier all Recall:  0.1\n",
      "RandomForestClassifier all fscore:  0.17142857142857143\n",
      "Decision Tree Imp Accuracy:  0.47540983606557374\n",
      "Decision Tree Imp Precision:  0.4\n",
      "Decision Tree Imp Recall:  0.13333333333333333\n",
      "Decision Tree Imp fscore:  0.2\n",
      "Decision Tree all Accuracy:  0.5245901639344263\n",
      "Decision Tree all Precision:  0.6\n",
      "Decision Tree all Recall:  0.1\n",
      "Decision Tree all fscore:  0.17142857142857143\n",
      "Naive Bayes Imp Accuracy:  0.5081967213114754\n",
      "Naive Bayes Imp Precision:  0.5\n",
      "Naive Bayes Imp Recall:  0.3333333333333333\n",
      "Naive Bayes Imp fscore:  0.4\n",
      "Naive Bayes all Accuracy:  0.47540983606557374\n",
      "Naive Bayes all Precision:  0.4722222222222222\n",
      "Naive Bayes all Recall:  0.5666666666666667\n",
      "Naive Bayes all fscore:  0.5151515151515152\n",
      "MLP Imp Accuracy:  0.4918032786885246\n",
      "MLP Imp Precision:  0.4918032786885246\n",
      "MLP Imp Recall:  1.0\n",
      "MLP Imp fscore:  0.6593406593406593\n",
      "MLP all Accuracy:  0.5081967213114754\n",
      "MLP all Precision:  0.0\n",
      "MLP all Recall:  0.0\n",
      "MLP all fscore:  0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "datasets = {'all_metrics': all_metrics, \n",
    "            'absolute': absolute, \n",
    "            'relative': relative, \n",
    "            'no_corr_metrics': no_corr_metrics}\n",
    "\n",
    "classifiers = {'RandomForestClassifier': RandomForestClassifier(n_estimators=100),\n",
    "               #'ExtraTreesClassifier': ExtraTreesClassifier(n_estimators=100),\n",
    "               #'XGBClassifier': XGBClassifier(),\n",
    "               'Decision Tree': DecisionTreeClassifier(),\n",
    "               'Naive Bayes': GaussianNB(),\n",
    "               'MLP' :MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "              }\n",
    "\n",
    "important_metrics = {'all_metrics': ['ntkn_count', 'loc_count', 'nkeys_count','ncd_count','etp_count',\n",
    "                                    'nnnv_count','nun_count','nts_count','ntun_count','nlp_count'],\n",
    "                    'absolute': ['ntkn_count', 'loc_count', 'nkeys_count','ncd_count','etp_count',\n",
    "                                    'nnnv_count','nun_count','nts_count','ntun_count','atss_count'],\n",
    "                    'relative': ['ntkn_count','loc_count','nkeys_count','ncd_count','nts_count',\n",
    "                                 'etp_count','ntvr_count','atss_count','nmd_count','nlp_count'],\n",
    "                     'no_corr_metrics': ['loc_count','atss_count','etp_count','nmd_count','nfl_count',\n",
    "                                         'nemd_count_relative','nlo_count','ntnn_count','nlp_count','nun_count_relative']\n",
    "                      }\n",
    "\n",
    "test_prior = pd.read_csv('results/metrics_prior.csv')\n",
    "test_fix = pd.read_csv('results/metrics_fix.csv')\n",
    "test_prior = test_prior.dropna()\n",
    "test_fix = test_fix.dropna()\n",
    "test = pd.concat([test_prior, test_fix])\n",
    "\n",
    "names_prior = [f.split(\"__\")[:2] for f in test_prior['file']]\n",
    "names_fix = [f.split(\"__\")[:2] for f in test_fix['file']]\n",
    "mapper = []\n",
    "for index, names in enumerate(names_prior):\n",
    "    if names in names_fix:\n",
    "        mapper.append([index, names_fix.index(names)])\n",
    "        \n",
    "mapper\n",
    "\n",
    "results = {}\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for df_name, data in datasets.items():\n",
    "    print(df_name)\n",
    "    metrics = important_metrics[df_name][:10]\n",
    "    results[df_name] = {}\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        results[df_name][clf_name] = {}\n",
    "        \n",
    "        X_train = np.array(data[metrics])\n",
    "        y_train = np.array(data['outlier'])\n",
    "        \n",
    "        X_test = test[metrics]\n",
    "        y_test = test['y']\n",
    "    \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        precision = precision_score(y_test, pred)\n",
    "        recall = recall_score(y_test, pred)\n",
    "        fscore =  f1_score(y_test, pred)\n",
    "        \n",
    "        results[df_name][clf_name]['important_accuracy'] = round(accuracy,2)\n",
    "        results[df_name][clf_name]['important_precision'] = round(precision,2)\n",
    "        results[df_name][clf_name]['important_recall'] = round(recall,2)\n",
    "        results[df_name][clf_name]['important_fscore'] = round(fscore,2)\n",
    "        \n",
    "        print(clf_name, \"Imp Accuracy: \", accuracy)\n",
    "        print(clf_name, \"Imp Precision: \", precision)\n",
    "        print(clf_name, \"Imp Recall: \", recall)\n",
    "        print(clf_name, \"Imp fscore: \", fscore)\n",
    "        \n",
    "        X_train = np.array(data[data.columns[:-1]])\n",
    "        y_train = np.array(data['outlier'])\n",
    "        \n",
    "        X_test = test[data.columns[:-1]]\n",
    "        y_test = test['y']\n",
    "    \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        precision = precision_score(y_test, pred)\n",
    "        recall = recall_score(y_test, pred)\n",
    "        fscore =  f1_score(y_test, pred)\n",
    "        \n",
    "        results[df_name][clf_name]['all_accuracy'] = round(accuracy,2)\n",
    "        results[df_name][clf_name]['all_precision'] = round(precision,2)\n",
    "        results[df_name][clf_name]['all_recall'] = round(recall,2)\n",
    "        results[df_name][clf_name]['all_fscore'] = round(fscore,2)\n",
    "        \n",
    "        print(clf_name, \"all Accuracy: \", accuracy)\n",
    "        print(clf_name, \"all Precision: \", precision)\n",
    "        print(clf_name, \"all Recall: \", recall)\n",
    "        print(clf_name, \"all fscore: \", fscore)\n",
    "        \n",
    "\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['all_prior', 'important_prior', 'all_fix','important_fix', 'all_recall', 'important recall', 'all_precision', 'important precision']\n",
    "\n",
    "res = pd.DataFrame.from_dict({(i,j): results[i][j] for i in results.keys() for j in results[i].keys()}, orient='index')\n",
    "nb_df = []\n",
    "for index, row in res.iterrows():\n",
    "    if 'Naive Bayes' in row.name:\n",
    "        nb_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrr}\n",
      "\\toprule\n",
      "                &     &  important\\_accuracy &  important\\_precision &  important\\_recall &  important\\_fscore &  all\\_accuracy &  all\\_precision &  all\\_recall &  all\\_fscore \\\\\n",
      "\\midrule\n",
      "all\\_metrics & RandomForestClassifier &                0.51 &                 0.50 &              0.10 &              0.17 &          0.52 &           0.57 &        0.13 &        0.22 \\\\\n",
      "                & Decision Tree &                0.49 &                 0.44 &              0.13 &              0.21 &          0.51 &           0.50 &        0.20 &        0.29 \\\\\n",
      "                & Naive Bayes &                0.49 &                 0.44 &              0.13 &              0.21 &          0.49 &           0.48 &        0.43 &        0.46 \\\\\n",
      "                & MLP &                0.49 &                 0.49 &              1.00 &              0.66 &          0.49 &           0.49 &        1.00 &        0.66 \\\\\n",
      "absolute & RandomForestClassifier &                0.49 &                 0.40 &              0.07 &              0.11 &          0.52 &           0.57 &        0.13 &        0.22 \\\\\n",
      "                & Decision Tree &                0.48 &                 0.43 &              0.20 &              0.27 &          0.52 &           0.57 &        0.13 &        0.22 \\\\\n",
      "                & Naive Bayes &                0.51 &                 0.50 &              0.10 &              0.17 &          0.52 &           0.52 &        0.43 &        0.47 \\\\\n",
      "                & MLP &                0.49 &                 0.49 &              1.00 &              0.66 &          0.51 &           0.00 &        0.00 &        0.00 \\\\\n",
      "relative & RandomForestClassifier &                0.51 &                 0.50 &              0.10 &              0.17 &          0.49 &           0.40 &        0.07 &        0.11 \\\\\n",
      "                & Decision Tree &                0.46 &                 0.36 &              0.13 &              0.20 &          0.51 &           0.50 &        0.10 &        0.17 \\\\\n",
      "                & Naive Bayes &                0.51 &                 0.50 &              0.20 &              0.29 &          0.51 &           0.50 &        0.43 &        0.46 \\\\\n",
      "                & MLP &                0.49 &                 0.49 &              1.00 &              0.66 &          0.51 &           0.00 &        0.00 &        0.00 \\\\\n",
      "no\\_corr\\_metrics & RandomForestClassifier &                0.51 &                 0.50 &              0.07 &              0.12 &          0.52 &           0.60 &        0.10 &        0.17 \\\\\n",
      "                & Decision Tree &                0.48 &                 0.40 &              0.13 &              0.20 &          0.52 &           0.60 &        0.10 &        0.17 \\\\\n",
      "                & Naive Bayes &                0.51 &                 0.50 &              0.33 &              0.40 &          0.48 &           0.47 &        0.57 &        0.52 \\\\\n",
      "                & MLP &                0.49 &                 0.49 &              1.00 &              0.66 &          0.51 &           0.00 &        0.00 &        0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(res).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_metrics\n",
      "RandomForestClassifier changes:  1\n",
      "RandomForestClassifier all changes:  2\n",
      "Decision Tree changes:  2\n",
      "Decision Tree all changes:  1\n",
      "Naive Bayes changes:  1\n",
      "Naive Bayes all changes:  2\n",
      "MLP changes:  0\n",
      "MLP all changes:  0\n",
      "\n",
      "absolute\n",
      "RandomForestClassifier changes:  0\n",
      "RandomForestClassifier all changes:  2\n",
      "Decision Tree changes:  2\n",
      "Decision Tree all changes:  2\n",
      "Naive Bayes changes:  1\n",
      "Naive Bayes all changes:  2\n",
      "MLP changes:  0\n",
      "MLP all changes:  0\n",
      "\n",
      "relative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:105: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier changes:  1\n",
      "RandomForestClassifier all changes:  0\n",
      "Decision Tree changes:  2\n",
      "Decision Tree all changes:  1\n",
      "Naive Bayes changes:  3\n",
      "Naive Bayes all changes:  2\n",
      "MLP changes:  0\n",
      "MLP all changes:  0\n",
      "\n",
      "no_corr_metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:105: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier changes:  0\n",
      "RandomForestClassifier all changes:  1\n",
      "Decision Tree changes:  0\n",
      "Decision Tree all changes:  1\n",
      "Naive Bayes changes:  3\n",
      "Naive Bayes all changes:  2\n",
      "MLP changes:  0\n",
      "MLP all changes:  0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kasper\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:105: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "datasets = {'all_metrics': all_metrics, \n",
    "            'absolute': absolute, \n",
    "            'relative': relative, \n",
    "            'no_corr_metrics': no_corr_metrics}\n",
    "\n",
    "classifiers = {'RandomForestClassifier': RandomForestClassifier(n_estimators=100),\n",
    "               #'ExtraTreesClassifier': ExtraTreesClassifier(n_estimators=100),\n",
    "               #'XGBClassifier': XGBClassifier(),\n",
    "               'Decision Tree': DecisionTreeClassifier(),\n",
    "               'Naive Bayes': GaussianNB(),\n",
    "               'MLP' :MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "              }\n",
    "\n",
    "important_metrics = {'all_metrics': ['ntkn_count', 'loc_count', 'nkeys_count','ncd_count','etp_count',\n",
    "                                    'nnnv_count','nun_count','nts_count','ntun_count','nlp_count'],\n",
    "                    'absolute': ['ntkn_count', 'loc_count', 'nkeys_count','ncd_count','etp_count',\n",
    "                                    'nnnv_count','nun_count','nts_count','ntun_count','atss_count'],\n",
    "                    'relative': ['ntkn_count','loc_count','nkeys_count','ncd_count','nts_count',\n",
    "                                 'etp_count','ntvr_count','atss_count','nmd_count','nlp_count'],\n",
    "                     'no_corr_metrics': ['loc_count','atss_count','etp_count','nmd_count','nfl_count',\n",
    "                                         'nemd_count_relative','nlo_count','ntnn_count','nlp_count','nun_count_relative']\n",
    "                      }\n",
    "\n",
    "test_prior = pd.read_csv('results/metrics_prior.csv')\n",
    "test_fix = pd.read_csv('results/metrics_fix.csv')\n",
    "test_prior = test_prior.dropna()\n",
    "test_fix = test_fix.dropna()\n",
    "test = pd.concat([test_prior, test_fix])\n",
    "\n",
    "names_prior = [f.split(\"__\")[:2] for f in test_prior['file']]\n",
    "names_fix = [f.split(\"__\")[:2] for f in test_fix['file']]\n",
    "mapper = []\n",
    "for index, names in enumerate(names_prior):\n",
    "    if names in names_fix:\n",
    "        mapper.append([index, names_fix.index(names)])\n",
    "        \n",
    "mapper\n",
    "\n",
    "results = {}\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for df_name, data in datasets.items():\n",
    "    print(df_name)\n",
    "    metrics = important_metrics[df_name][:10]\n",
    "    results[df_name] = {}\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        results[df_name][clf_name] = {}\n",
    "        \n",
    "        X_train = np.array(data[metrics])\n",
    "        y_train = np.array(data['outlier'])\n",
    "        \n",
    "        X_test_prior = test_prior[metrics]\n",
    "        y_test_prior = test_prior['y']\n",
    "        \n",
    "        X_test_fix = test_fix[metrics]\n",
    "        y_test_fix = test_fix['y']\n",
    "    \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predict_prior = clf.predict(X_test_prior)\n",
    "        predict_fix = clf.predict(X_test_fix)\n",
    "        score_prior = accuracy_score(y_test_prior, predict_prior)\n",
    "        score_fix = accuracy_score(y_test_fix, predict_fix)\n",
    "        precision = sum(predict_prior)/(sum(predict_prior) + sum(predict_fix))\n",
    "        recall = sum(predict_prior)/(sum(predict_prior) + (predict_prior==0).sum())\n",
    "        \n",
    "        score_prior = accuracy_score(y_test_prior, clf.predict(X_test_prior))\n",
    "        score_fix = accuracy_score(y_test_fix, clf.predict(X_test_fix))\n",
    "        \n",
    "        change_pred = []\n",
    "        for i,j in mapper:\n",
    "            change_pred.append([predict_prior[i], predict_fix[j]])\n",
    "        correct_change_pred = [i for i in change_pred if i[0]==1 and i[1]==0]\n",
    "        \n",
    "        results[df_name][clf_name]['important changes'] = len(correct_change_pred)\n",
    "        results[df_name][clf_name]['important_prior'] = score_prior\n",
    "        results[df_name][clf_name]['important_fix'] = score_fix\n",
    "        results[df_name][clf_name]['important precision'] = precision\n",
    "        results[df_name][clf_name]['important recall'] = recall\n",
    "        \n",
    "#         print(name, \"Precision: \", precision)\n",
    "#         print(name, \"Recall: \", recall)\n",
    "#         print(name, \" important metrics prior:\", accuracy_score(y_test_prior, clf.predict(X_test_prior)))\n",
    "#         print(name, \" important metrics fix:\", accuracy_score(y_test_fix, clf.predict(X_test_fix)))\n",
    "        print(clf_name, \"changes: \", len(correct_change_pred))\n",
    "        \n",
    "        X_train = np.array(data[data.columns[:-1]])\n",
    "        y_train = np.array(data['outlier'])\n",
    "        \n",
    "        X_test_prior = test_prior[data.columns[:-1]]\n",
    "        y_test_prior = test_prior['y']\n",
    "        \n",
    "        X_test_fix = test_fix[data.columns[:-1]]\n",
    "        y_test_fix = test_fix['y']\n",
    "    \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predict_prior = clf.predict(X_test_prior)\n",
    "        predict_fix = clf.predict(X_test_fix)\n",
    "        score_prior = accuracy_score(y_test_prior, predict_prior)\n",
    "        score_fix = accuracy_score(y_test_fix, predict_fix)\n",
    "        precision = sum(predict_prior)/(sum(predict_prior) + sum(predict_fix))\n",
    "        recall = sum(predict_prior)/(sum(predict_prior) + (predict_prior==0).sum())\n",
    "        \n",
    "        change_pred = []\n",
    "        for i,j in mapper:\n",
    "            change_pred.append([predict_prior[i], predict_fix[j]])\n",
    "        correct_change_pred = [i for i in change_pred if i[0]==1 and i[1]==0]\n",
    "        \n",
    "        results[df_name][clf_name]['all changes'] = len(correct_change_pred)\n",
    "        results[df_name][clf_name]['all_prior'] = score_prior\n",
    "        results[df_name][clf_name]['all_fix'] = score_fix\n",
    "        results[df_name][clf_name]['all_precision'] = precision\n",
    "        results[df_name][clf_name]['all_recall'] = recall\n",
    "        \n",
    "        \n",
    "#         print(name, \"Precision: \", precision)\n",
    "#         print(name, \"Recall: \", recall)\n",
    "#         print(name, \" all metrics prior:\", accuracy_score(y_test_prior, clf.predict(X_test_prior)))\n",
    "#         print(name, \" all metrics fix:\", accuracy_score(y_test_fix, clf.predict(X_test_fix)))\n",
    "        print(clf_name, \"all changes: \", len(correct_change_pred))\n",
    "        \n",
    "\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
